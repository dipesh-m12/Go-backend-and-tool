package main

import (
	"bytes"
	"crypto/tls"
	"flag"
	"fmt"
	"io"
	"log"
	"net/http"
	"os"
	"runtime"
	"sort"
	"strings"
	"sync"
	"sync/atomic"
	"time"
)

// Tool branding and version
const (
	toolName    = "panty"
	toolVersion = "1.0.0"
	asciiArt    = `
██████   █████  ███    ██ ████████ ██    ██ 
██   ██ ██   ██ ████   ██    ██     ██  ██  
██████  ███████ ██ ██  ██    ██      ████   
██      ██   ██ ██  ██ ██    ██       ██    
██      ██   ██ ██   ████    ██       ██    
                                           
          ~ CLI Tool v1.0.0 ~
`
)


// RequestResult holds the outcome of a single HTTP request
type RequestResult struct {
	StatusCode int
	Latency    time.Duration
	Err        error
}

// Global statistics
var (
	successCount  uint64 // Atomic counter for successful requests (meaning "sent" in fire-and-forget mode)
	failureCount  uint64 // Atomic counter for failed requests (meaning "client-side error sending" in fire-and-forget mode)
	totalLatency  int64  // Atomic sum of all latencies in nanoseconds (only for full-response mode)
	allLatencies  []time.Duration // Only for full-response mode
	latenciesMutex sync.Mutex // Mutex to protect allLatencies slice
)

func printBanner() {
	fmt.Println(asciiArt)
	fmt.Printf("  %s - Version %s\n", toolName, toolVersion)
	fmt.Println("  A powerful CLI tool for local server load & health testing.")
	fmt.Println("----------------------------------------------------------")
}

func main() {
	// Setup logging initially. This can be overridden by flags later.
	log.SetOutput(io.Discard) // Discard logs by default
	log.SetFlags(log.Ldate | log.Ltime | log.Lshortfile)

	// Command line flags for configuration
	versionFlag := flag.Bool("version", false, "Display version information and exit")
	url := flag.String("url", "", "Target URL to test (e.g., http://localhost:8080/health)")
	numRequests := flag.Int("n", 0, "Number of requests to send (mutually exclusive with -duration)")
	concurrency := flag.Int("c", runtime.NumCPU()*2, "Number of concurrent workers (default: 2 * CPU cores)")
	method := flag.String("method", "GET", "HTTP method to use (e.g., GET, POST, PUT, DELETE)")
	timeout := flag.Int("timeout", 10, "Timeout for each request in seconds")
	data := flag.String("data", "", "Request body data (e.g., '{\"key\":\"value\"}' for POST/PUT)")
	headers := flag.String("H", "", "Custom headers, comma-separated 'Key1: Value1,Key2: Value2'")
	durationStr := flag.String("duration", "", "Duration to run the test (e.g., '30s', '5m', mutually exclusive with -n)")
	silent := flag.Bool("silent", false, "Suppress per-request output logs")
	insecureSkipVerify := flag.Bool("k", false, "Skip TLS certificate verification (insecure!)")
	verbose := flag.Bool("v", false, "Enable verbose logging for each request (includes health checks)")
	healthIntervalStr := flag.String("health-interval", "", "Interval for periodic health checks (e.g., '5s', '1m'). If empty, no health checks.")
	fireAndForget := flag.Bool("fire-and-forget", false, "If true, main load test workers send requests without waiting for full server response (disables latency/status metrics for main load).")

	flag.Parse()

	// Handle version flag immediately
	if *versionFlag {
		printBanner()
		return // Exit after printing version
	}

	printBanner() // Print banner for normal execution

	// Enable verbose logging for all output if requested
	if *verbose {
		log.SetOutput(os.Stderr)
	} else if *healthIntervalStr != "" {
		// If only health checks are active and not verbose, still show health logs
		log.SetOutput(os.Stderr)
	}

	// Validate flags
	if *url == "" {
		log.Fatal("Error: Target URL is required. Use -url flag. Use --help for usage.")
	}
	if *numRequests == 0 && *durationStr == "" && *healthIntervalStr == "" {
		log.Fatal("Error: Either -n (number of requests), -duration, or -health-interval must be specified to run a test. Use --help for usage.")
	}
	if *numRequests > 0 && *durationStr != "" {
		log.Fatal("Error: -n and -duration flags are mutually exclusive. Please choose one. Use --help for usage.")
	}

	// Adjust GOMAXPROCS to utilize all CPU cores
	runtime.GOMAXPROCS(runtime.NumCPU())
	fmt.Printf("Using %d CPU cores.\n", runtime.NumCPU())
	if *fireAndForget {
		fmt.Println("Running in FIRE-AND-FORGET mode for main load test. No detailed response metrics will be collected for these requests.")
	}

	// Parse test duration if provided
	var testDuration time.Duration
	var err error
	if *durationStr != "" {
		testDuration, err = time.ParseDuration(*durationStr)
		if err != nil {
			log.Fatalf("Error parsing duration: %v. Use --help for usage.", err)
		}
	}

	// Parse health check interval if provided
	var healthInterval time.Duration
	if *healthIntervalStr != "" {
		healthInterval, err = time.ParseDuration(*healthIntervalStr)
		if err != nil {
			log.Fatalf("Error parsing health-interval: %v. Use --help for usage.", err)
		}
		if healthInterval <= 0 {
			log.Fatal("Error: health-interval must be a positive duration. Use --help for usage.")
		}
	}

	// Create a custom HTTP client with timeout and transport settings for the main load
	tr := &http.Transport{
		MaxIdleConns:        *concurrency * 2,
		MaxIdleConnsPerHost: *concurrency,
		DisableKeepAlives:   false, // Keep-alives are generally better for performance
		TLSClientConfig:     &tls.Config{InsecureSkipVerify: *insecureSkipVerify},
	}
	client := &http.Client{
		Timeout:   time.Duration(*timeout) * time.Second,
		Transport: tr,
	}

	// Create a separate client for health checks to avoid affecting main load metrics
	// and to have potentially different timeout/settings for critical monitoring
	healthClient := &http.Client{
		Timeout:   5 * time.Second, // Shorter, dedicated timeout for health checks
		Transport: &http.Transport{
			TLSClientConfig: &tls.Config{InsecureSkipVerify: *insecureSkipVerify},
		},
	}

	// Parse custom headers
	customHeaders := make(map[string]string)
	if *headers != "" {
		headerPairs := strings.Split(*headers, ",")
		for _, pair := range headerPairs {
			parts := strings.SplitN(strings.TrimSpace(pair), ":", 2)
			if len(parts) == 2 {
				customHeaders[strings.TrimSpace(parts[0])] = strings.TrimSpace(parts[1])
			} else {
				log.Printf("Warning: Malformed header: %s. Skipping.", pair)
			}
		}
	}

	// Channel to feed work to workers
	jobs := make(chan int, *concurrency)
	results := make(chan RequestResult, *concurrency) // Results are still collected for client-side errors in F&F mode

	var wg sync.WaitGroup // WaitGroup for workers

	// Start worker goroutines
	for w := 1; w <= *concurrency; w++ {
		wg.Add(1)
		// Pass the fireAndForget flag to the worker
		go worker(w, jobs, results, client, *url, *method, *data, customHeaders, *silent, *fireAndForget, &wg)
	}

	// Goroutine to collect results (for client-side errors in F&F mode, and full metrics otherwise)
	go func() {
		for res := range results {
			if res.Err != nil {
				atomic.AddUint64(&failureCount, 1)
				if *verbose {
					log.Printf("Request failed: %v", res.Err)
				}
			} else {
				atomic.AddUint64(&successCount, 1)
				// Only add latency if not in fire-and-forget mode, as latency is meaningless otherwise
				if !*fireAndForget {
					atomic.AddInt64(&totalLatency, res.Latency.Nanoseconds())
					latenciesMutex.Lock()
					allLatencies = append(allLatencies, res.Latency)
					latenciesMutex.Unlock()
				}
			}
		}
	}()

	fmt.Printf("Starting load test with %d concurrent workers...\n", *concurrency)
	startTime := time.Now()

	// Channel to signal health checker to stop
	stopHealthCheck := make(chan struct{})
	// Channel for health check to signal main to stop test
	terminateTestChan := make(chan struct{}, 1) // Buffered to prevent blocking if main is busy

	// Start periodic health checks if interval is provided
	if healthInterval > 0 {
		// Pass method, data, and headers to health check
		go periodicHealthCheck(*url, *method, *data, customHeaders, healthInterval, healthClient, stopHealthCheck, terminateTestChan)
	}

	// Channel to signal when primary job sending should cease (duration or num requests met)
	loadGenerationDone := make(chan struct{})

	// Goroutine for sending jobs (primary load generation)
	go func() {
		defer close(loadGenerationDone) // Ensure this is closed when load generation stops

		if *numRequests > 0 {
			for i := 1; i <= *numRequests; i++ {
				jobs <- i
			}
		} else if testDuration > 0 {
			numSent := 0
			for {
				select {
				case <-time.After(testDuration):
					log.Println("Load generation duration elapsed.")
					return // Exit this goroutine, closing loadGenerationDone via defer
				case jobs <- numSent: // Continuously send jobs
					numSent++
				}
			}
		} else { // No -n or -duration, but health-interval exists, run indefinitely (or until terminated by health check)
			select{} // Block indefinitely until explicitly terminated by health check or Ctrl+C
		}
	}()

	// Wait for either the load generation to complete or health check to signal termination
	select {
	case <-loadGenerationDone:
		// Primary load generation completed naturally
		log.Println("Main load generation completed. Allowing active requests to finish...")
	case <-terminateTestChan:
		// Health check signaled termination
		log.Println("Test terminated by health check failure!")
		// Explicitly close jobs channel if termination came from health check
		// This will cause workers to exit their loops faster.
		select {
		case <-jobs: // Check if jobs is already closed/drained
			// Already closed or drained, do nothing
		default:
			close(jobs) // Close jobs to signal workers to stop accepting new tasks
		}
	}

	// Stop the periodic health check goroutine immediately now that the main test
	// (or its termination) decision has been made.
	if healthInterval > 0 {
		close(stopHealthCheck)
	}

	// Wait for all worker goroutines to finish their current requests
	// This ensures accurate final metrics for what was processed.
	wg.Wait()

	// Close the results channel after all workers have finished sending results
	close(results)

	// Calculate the actual duration of the test
	actualDuration := time.Since(startTime)

	// Give a small buffer for results aggregator to finish
	time.Sleep(100 * time.Millisecond)

	printSummary(actualDuration, atomic.LoadUint64(&successCount), atomic.LoadUint64(&failureCount), concurrency, *fireAndForget)
}

// worker function sends HTTP requests and reports results
// Behavior changes based on the fireAndForget flag
func worker(id int, jobs <-chan int, results chan<- RequestResult, client *http.Client, url, method, data string, customHeaders map[string]string, silent, fireAndForget bool, wg *sync.WaitGroup) {
	defer wg.Done()

	for range jobs { // Loop continues as long as jobs channel is open and has values
		var reqBody io.Reader
		if data != "" {
			reqBody = bytes.NewBufferString(data)
		}

		req, err := http.NewRequest(method, url, reqBody)
		if err != nil {
			results <- RequestResult{Err: fmt.Errorf("error creating request: %w", err)}
			if !silent {
				log.Printf("Worker %d: Error creating request to %s (%s): %v\n", id, url, method, err)
			}
			continue
		}

		// Set default headers
		req.Header.Set("User-Agent", "GoPentester/1.0")
		req.Header.Set("Accept", "*/*")
		// Set Content-Type only if method is POST/PUT and it's not already set by custom headers
		if (method == "POST" || method == "PUT") && req.Header.Get("Content-Type") == "" && data != "" {
			req.Header.Set("Content-Type", "application/json")
		}

		start := time.Now()
		resp, err := client.Do(req) // This still awaits initial response, but handling differs

		if fireAndForget {
			// In fire-and-forget mode, we only care if the request could be sent at all (client-side errors)
			if err != nil {
				results <- RequestResult{Err: fmt.Errorf("request sending failed: %w", err)}
				if !silent {
					log.Printf("Worker %d: Fire-and-Forget request to %s (%s) failed sending: %v\n", id, url, method, err)
				}
			} else {
				// Successfully sent, close body immediately without reading to maximize throughput
				if resp != nil && resp.Body != nil {
					resp.Body.Close()
				}
				results <- RequestResult{} // Send a successful empty result
				if !silent {
					log.Printf("Worker %d: Fire-and-Forget request to %s (%s) sent successfully.\n", id, url, method)
				}
			}
			continue // Move to the next job immediately
		}

		// Default behavior (not fire-and-forget) - await full response and collect metrics
		latency := time.Since(start)
		if err != nil {
			results <- RequestResult{Err: fmt.Errorf("request error: %w", err), Latency: latency}
			if !silent {
				log.Printf("Worker %d: Request to %s (%s) failed: %v (Latency: %s)\n", id, url, method, err, latency)
			}
			continue
		}
		defer resp.Body.Close() // Ensure body is closed to reuse connection

		// Read and discard response body to ensure connection is ready for reuse
		// This is crucial for accurate latency measurement and connection pooling efficiency
		_, readErr := io.Copy(io.Discard, resp.Body)
		if readErr != nil {
			log.Printf("Worker %d: Error reading response body: %v\n", id, readErr)
		}

		results <- RequestResult{StatusCode: resp.StatusCode, Latency: latency}
		if !silent {
			log.Printf("Worker %d: Request to %s (%s) completed with status %d (Latency: %s)\n", id, url, method, resp.StatusCode, latency)
		}
	}
}

// periodicHealthCheck performs a request to the target URL at a given interval.
// It uses the same method, data, and headers as the main load test.
// It signals termination if a non-healthy status is detected.
func periodicHealthCheck(url, method, data string, customHeaders map[string]string, interval time.Duration, client *http.Client, stop <-chan struct{}, terminateTestChan chan<- struct{}) {
	ticker := time.NewTicker(interval)
	defer ticker.Stop()

	log.Printf("Starting periodic health checks to %s (method: %s) every %s", url, method, interval)

	for {
		select {
		case <-ticker.C:
			var reqBody io.Reader
			if data != "" {
				reqBody = bytes.NewBufferString(data) // Create a new reader for each request
			}

			req, err := http.NewRequest(method, url, reqBody)
			if err != nil {
				log.Printf("[HEALTH CHECK] %s - FATAL: Error creating request: %v", time.Now().Format("15:04:05"), err)
				select {
				case terminateTestChan <- struct{}{}: // Attempt to signal termination
				default: // Non-blocking send
				}
				return // Exit this goroutine
			}
			req.Header.Set("User-Agent", "GoPentester/HealthCheck")
			// Apply custom headers for health check
			for k, v := range customHeaders {
				req.Header.Set(k, v)
			}
			// Set Content-Type for POST/PUT if data is present and not explicitly set by custom headers
			if (method == "POST" || method == "PUT") && data != "" && req.Header.Get("Content-Type") == "" {
				req.Header.Set("Content-Type", "application/json")
			}

			start := time.Now()
			resp, err := client.Do(req) // This always awaits the full response for health checks
			latency := time.Since(start)

			if err != nil {
				// Network or connection error - highly indicative of server being down
				log.Printf("[HEALTH CHECK] %s - Server is DOWN (Connection/Network Error): %v (Latency: %s)", time.Now().Format("15:04:05"), err, latency)
				select {
				case terminateTestChan <- struct{}{}: // Attempt to signal termination
				default:
				}
				return // Exit this goroutine
			} else {
				defer resp.Body.Close()
				// Read and discard response body for the health check itself
				_, readErr := io.Copy(io.Discard, resp.Body)
				if readErr != nil {
					log.Printf("[HEALTH CHECK] %s - Status %d, Error reading body: %v (Latency: %s)", time.Now().Format("15:04:05"), resp.StatusCode, readErr, latency)
				}

				if resp.StatusCode >= 200 && resp.StatusCode < 300 {
					log.Printf("[HEALTH CHECK] %s - Server is HEALTHY (Status Code: %d) (Latency: %s)", time.Now().Format("15:04:05"), resp.StatusCode, latency)
					// Do not terminate, continue monitoring
				} else if resp.StatusCode >= 500 && resp.StatusCode < 600 {
					log.Printf("[HEALTH CHECK] %s - Server is EXPERIENCING ISSUES (Status Code: %d) (Latency: %s)", time.Now().Format("15:04:05"), resp.StatusCode, latency)
					select {
					case terminateTestChan <- struct{}{}: // Attempt to signal termination
					default:
					}
					return // Exit this goroutine
				} else {
					log.Printf("[HEALTH CHECK] %s - Server responded with UNEXPECTED STATUS (Status Code: %d) (Latency: %s)", time.Now().Format("15:04:05"), resp.StatusCode, latency)
					select {
					case terminateTestChan <- struct{}{}: // Attempt to signal termination
					default:
					}
					return // Exit this goroutine
				}
			}
		case <-stop:
			log.Println("Stopping periodic health checks.")
			return // Exit this goroutine
		}
	}
}

// printSummary calculates and prints the final statistics
func printSummary(duration time.Duration, success, failure uint64, concurrency *int, fireAndForget bool) {
	totalRequests := success + failure
	if totalRequests == 0 {
		fmt.Println("\nNo requests were made during the test.")
		return
	}

	fmt.Println("\n--- Load Test Summary ---")
	fmt.Printf("Total Requests Sent (Client-Side): %d\n", totalRequests)
	if fireAndForget {
		fmt.Println("Note: Running in FIRE-AND-FORGET mode. 'Successful Requests' means requests initiated without client-side network errors. Response status and true latency are not measured for these requests.")
	} else {
		fmt.Printf("Successful Requests (Server Response 2xx): %d\n", success)
	}

	fmt.Printf("Failed Requests (Client-Side Errors): %d\n", failure)
	fmt.Printf("Concurrency Level: %d\n", *concurrency)
	fmt.Printf("Test Duration: %.2f seconds\n", duration.Seconds())

	if !fireAndForget && success > 0 {
		requestsPerSecond := float64(success) / duration.Seconds()
		avgLatency := time.Duration(atomic.LoadInt64(&totalLatency) / int64(success))

		fmt.Printf("Requests per second (successful responses): %.2f req/s\n", requestsPerSecond)
		fmt.Printf("Average Latency: %s\n", avgLatency)

		latenciesMutex.Lock()
		sort.Slice(allLatencies, func(i, j int) bool {
			return allLatencies[i] < allLatencies[j]
		})

		minLatency := allLatencies[0]
		maxLatency := allLatencies[len(allLatencies)-1]
		medianLatency := getPercentile(allLatencies, 50)
		p90Latency := getPercentile(allLatencies, 90)
		p95Latency := getPercentile(allLatencies, 95)
		p99Latency := getPercentile(allLatencies, 99)
		latenciesMutex.Unlock()

		fmt.Println("\n--- Latency Distribution (for successful responses) ---")
		fmt.Printf("Min:    %s\n", minLatency)
		fmt.Printf("Max:    %s\n", maxLatency)
		fmt.Printf("Median: %s\n", medianLatency)
		fmt.Printf("P90:    %s\n", p90Latency)
		fmt.Printf("P95:    %s\n", p95Latency)
		fmt.Printf("P99:    %s\n", p99Latency)
	} else if !fireAndForget && success == 0 {
		fmt.Println("\nNo successful responses to calculate latency statistics in non-fire-and-forget mode.")
	} else if fireAndForget {
		fmt.Println("\nLatency statistics are not available in FIRE-AND-FORGET mode.")
	}

	if failure > 0 {
		fmt.Printf("\nFailure Rate (Client-Side): %.2f%%\n", float64(failure)/float64(totalRequests)*100)
	}

	fmt.Println("\n--- End of Test ---")
}

// getPercentile calculates the Nth percentile from a sorted slice of durations
func getPercentile(latencies []time.Duration, percentile int) time.Duration {
	if len(latencies) == 0 {
		return 0
	}
	if percentile <= 0 {
		return latencies[0]
	}
	if percentile >= 100 {
		return latencies[len(latencies)-1]
	}
	index := (float64(percentile) / 100.0) * float64(len(latencies)-1)
	return latencies[int(index)]
}

